[settings]
# 1 true, 0 false
save_models = 1

[dataset]
file = SQLiV3.tsv
#file = toy.tsv

[data_manager]
seed = 13, 27, 42, 72, 84, 91, 94, 101, 333, 666
split_ratio = 0.2

[feature_methods]
# methods = tf-idf, tf-idf_ngram, bag_of_words, bag_of_characters
#methods = tf-idf, tf-idf_ngram, bag_of_characters
methods = tf-idf_ngram

[models]
# XGBoost, MultinomialNB, SVM_RBF, MLPClassifier, KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier, SVC-GC, NuSVC, LinearSVC, DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RidgeClassifier, SGDClassifier, Perceptron, LogisticRegression, PassiveAggressiveClassifier, OneVsRestClassifier, OneVsOneClassifier,
# bad
classic_models = XGBoost, MultinomialNB, SVM_RBF, MLPClassifier, KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier, SVC-GC, NuSVC, LinearSVC, DecisionTreeClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RidgeClassifier, SGDClassifier, Perceptron, LogisticRegression, PassiveAggressiveClassifier, OneVsRestClassifier, OneVsOneClassifier
# classic_models = XGBoost, MultinomialNB, KNeighborsClassifier
dir = trained_models

[results]
dir = results